{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa7b1926",
   "metadata": {},
   "source": [
    "# Fire Detection From Images and Videos' Using YOLOv5\n",
    "By Arafat Islam, Rifat Ahmed\n",
    "- This program was writen in the google colab but for the sunmission it is downloaded as ipynb file.\n",
    "\n",
    "# N.B. If you run this program in jupyter file it will not work if you don't have GPU. And even if you have GPU you need to configure environment for the GPU. We developed this in Google Colab and for the submission we make this file because from Colab we can download file either as .ipnb or as .py extension. \n",
    "\n",
    "- YOLOv5 official github link: https://github.com/ultralytics/yolov5) by [Ultralytics](https://www.ultralytics.com/). \n",
    "\n",
    "To train our model we take the following steps:\n",
    "\n",
    "* Install YOLOv5 dependencies\n",
    "* Download custom YOLOv5 object detection data\n",
    "* Write our YOLOv5 Training configuration\n",
    "* Run YOLOv5 training\n",
    "* Evaluate YOLOv5 performance\n",
    "* Visualize YOLOv5 training data\n",
    "* Export saved YOLOv5 weights for future inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d878202",
   "metadata": {},
   "source": [
    "# Install Dependencies\n",
    "- From official github repository of YOLOv5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone YOLOv5 repository\n",
    "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
    "%cd yolov5\n",
    "!git reset --hard fbe67e465375231474a2ad80a4389efc77ecff99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies as necessary\n",
    "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
    "import torch\n",
    "\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "from utils.downloads import attempt_download  # to download models/datasets\n",
    "\n",
    "# clear_output()\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee58002",
   "metadata": {},
   "source": [
    "# Download Correctly Formatted Custom Dataset \n",
    "\n",
    "We stored our dataset in Robofloy and data were preprocessed using this model. \n",
    "We'll download our dataset from Roboflow. Use the \"**YOLOv5 PyTorch**\" export format. Note that the Ultralytics implementation calls for a YAML file defining where your training and test data is. The Roboflow export also writes this format for us.\n",
    "\n",
    "- Roboflow creates an API link which we will directly use. And the program will download the dataset with the labels in YOLOv5 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c66207",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install roboflow\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"7cKtzsjt0qeY9KZOL7Ax\")\n",
    "project = rf.workspace(\"aiub-j9lom\").project(\"largest-dataset\")\n",
    "dataset = project.version(1).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506471bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change directory\n",
    "%cd /content/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0f896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
    "%cat {dataset.location}/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d3cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model Configuration and Architecture\n",
    "\n",
    "We will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dd93da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of classes based on YAML\n",
    "import yaml\n",
    "with open(dataset.location + \"/data.yaml\", 'r') as stream:\n",
    "    num_classes = str(yaml.safe_load(stream)['nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8731eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the model yoloV5X configuration we are going to use.\n",
    "%cat /content/yolov5/models/yolov5x.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a47a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#customize iPython writefile so we can write variables\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03f8ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate /content/yolov5/models/custom_yolov5x.yaml\n",
    "\n",
    "# parameters\n",
    "nc: {num_classes}  # number of classes\n",
    "\n",
    "depth_multiple: 1.33  # model depth multiple\n",
    "width_multiple: 1.25  # layer channel multiple\n",
    "anchors:\n",
    "  - [10,13, 16,30, 33,23]  # P3/8\n",
    "  - [30,61, 62,45, 59,119]  # P4/16\n",
    "  - [116,90, 156,198, 373,326]  # P5/32\n",
    "\n",
    "# YOLOv5 v6.0 backbone\n",
    "backbone:\n",
    "  # [from, number, module, args]\n",
    "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
    "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
    "   [-1, 3, C3, [128]],\n",
    "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
    "   [-1, 6, C3, [256]],\n",
    "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
    "   [-1, 9, C3, [512]],\n",
    "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
    "   [-1, 3, C3, [1024]],\n",
    "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
    "  ]\n",
    "\n",
    "# YOLOv5 v6.0 head\n",
    "head:\n",
    "  [[-1, 1, Conv, [512, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
    "   [-1, 3, C3, [512, False]],  # 13\n",
    "\n",
    "   [-1, 1, Conv, [256, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
    "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
    "\n",
    "   [-1, 1, Conv, [256, 3, 2]],\n",
    "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
    "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
    "\n",
    "   [-1, 1, Conv, [512, 3, 2]],\n",
    "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
    "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
    "\n",
    "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb347ac4",
   "metadata": {},
   "source": [
    "# Train YOLOv5 Model\n",
    "\n",
    "### Next, we'll fire off training!\n",
    "\n",
    "\n",
    "Here, we are able to pass a number of arguments:\n",
    "- **img:** define input image size\n",
    "- **batch:** determine batch size\n",
    "- **epochs:** define the number of training epochs. (Note: often, 300 are common here!) But we will use 200 as the limitation of GPU.\n",
    "- **data:** set the path to our yaml file\n",
    "- **cfg:** specify our model configuration\n",
    "- **weights:** specify a custom path to weights. (Note: you can download weights from the Ultralytics Google Drive [folder](https://drive.google.com/open?id=1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J))\n",
    "- **name:** result names\n",
    "- **nosave:** only save the final checkpoint\n",
    "- **cache:** cache images for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa95dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat /content/yolov5/models/custom_yolov5x.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f857704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train yolov5X on custom data for 100 epochs\n",
    "# time its performance\n",
    "# The program will not run here as we did notprepare the jupyter notebook for runing on gpu.\n",
    "# We trained our model in Google Colab and it runs on GPU.\n",
    "%%time\n",
    "%cd /content/yolov5/\n",
    "!python train.py --img 416 --batch 64 --epochs 200 --data {dataset.location}/data.yaml --cfg ./models/custom_yolov5x.yaml --weights '' --name yolov5x_results  --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e754d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate YOLOv5 Detector Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c682b42",
   "metadata": {},
   "source": [
    "Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolov5x_results`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes.\n",
    "\n",
    "Note from Glenn: Partially completed `results.txt` files can be plotted with `from utils.utils import plot_results; plot_results()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f237bb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5c91c8d12f4bf5df\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5c91c8d12f4bf5df\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard\n",
    "# Launch after you have started training\n",
    "# logs save in the folder \"runs\"\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df3d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also output some older school graphs if the tensor board isn't working for whatever reason... \n",
    "from utils.plots import plot_results  # plot results.txt as results.png\n",
    "Image(filename='/content/yolov5/runs/train/yolov5s_results/results.png', width=1000)  # view results.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcad9ed",
   "metadata": {},
   "source": [
    "###  Visualize Our Training Data with Labels\n",
    "\n",
    "After training starts, view `train*.jpg` images to see training images, labels and augmentation effects.\n",
    "\n",
    "Note a mosaic dataloader is used for training (shown below), a new dataloading concept developed by Glenn Jocher and first featured in [YOLOv4](https://arxiv.org/abs/2004.10934)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941e07ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, display our ground truth data\n",
    "print(\"GROUND TRUTH TRAINING DATA:\")\n",
    "Image(filename='/content/yolov5/runs/train/yolov5x_results/test_batch0_labels.jpg', width=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c641ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out an augmented training example\n",
    "print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n",
    "Image(filename='/content/yolov5/runs/train/yolov5x_results/train_batch0.jpg', width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d79c81d",
   "metadata": {},
   "source": [
    "# Run Inference  With Trained Weights\n",
    "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3921b15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls runs/train/yolov5s_results/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56168ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when we ran this, we saw .07 second inference time. That is 140 FPS on a TESLA P100!\n",
    "# use the best weights!\n",
    "%cd /content/yolov5/\n",
    "!python detect.py --weights runs/train/yolov5x_results/weights/best.pt --img 416 --conf 0.4 --source ../test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81140a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display inference on ALL test images\n",
    "#this looks much better with longer training above\n",
    "\n",
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
    "    display(Image(filename=imageName))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefa1cf4",
   "metadata": {},
   "source": [
    "# Export Trained Weights for Future Inference\n",
    "\n",
    "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0bad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4051c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cp /content/yolov5/runs/train/yolov5x_results/weights/best.pt /content/gdrive/My\\ Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cad0638",
   "metadata": {},
   "source": [
    "# YOLOv5x Model building, training and validation is done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
